 关键词：总结、基于hash一致性思想的表分区嵌套设计
        过去的一个阶段，我参与了公司机密级别技术的研发，负责了一个核心模块，在本文我希望回顾这一经历，给自己一些启发。
        入职数月，承蒙领导抬爱，安排我负责分布式数据库内核存储引擎的一个优化方案的实现，该优化的上层目标是为了支撑华为终端等业务的快速增长。已有的集群规模无法满足业务的快速增长带来数据存储规模增大的压力，这要求集群更快更高效的扩容并将原有集群节点上的数据重分布到现有的所有节点上。原有的扩容重分布耗时是小时级别的，新的优化方案成功将时间优化到了分钟级别。
         公司的这个不允许对外公开的分布式数据的架构有点类似开源的 PostgreSQL-XC（PG-XC）。PG-XC 的架构涉及 NodeGroup （节点组）、CN（管理节点）、DN（数据节点）等，具体可以上网查阅。我们知道常见的数据库都有分区的设计，并支持扩容重分布这一功能。所谓扩容就是增多节点数量来增大集群容量，在扩容时或扩容后需要将原有节点上的一些数据搬移到新的节点上，低效的扩容重分布方案，会对整个分区甚至整个表的数据进行全部扫描后然后插入到新的节点的新的分区或新的表上，这样的方案下，数据搬移粒度大，耗时多。实际上，数据按照新的路由规则重新计算后，并不需要搬移一整个分区的数据，为了细粒度化搬移的数据单位，我们复用了原有的分区结构，在原有的分区下嵌套了一层新的分区，将其称之为hash bucket，我们将 bucket 功能设计成了一个可定制的开关，一张表如果打开了 bucket 开关，这张表上对应的用户表和表分区都会成为逻辑表，用来记录实际数据存储单位 bucket 表的元信息。在新的设计中一项数据和所在 DN 的映射信息会被记录在 CN 的一个 BucketMap 结构（类似于 Cache）中，数据的 DDL 和 DML 操作落到 CN 上后会通过 BucketMap 中记录的路由信息进一步分发到对应的各个 DN 上。

  新的数据存储方案的好处有：
1. 数据搬迁前不再需要全表扫描，只需要按照一种比分区更小的数据粒度进行扫描，大量缩减了搬移耗时。
2. 在计算分离场景中，只需要修改文件映射（在内存中体现为BucketMap）即可实现扩容，因为不需要移动物理文件。
3. 索引重新建立，只会对新节点上生成的hash bucket数据文件进行索引重建，不需要对所有数据进行重建，且不会影响原表的在线业务。

          由于公司的保密规定，这里就不对 hash bucket 的深入设计和系统整体的详细设计做过多描述了，以免触碰公司红线，被查水表甚至招来官司。
